---
title: "Landfill Geographic Analysis"
output: html_document
date: "2024-01-11"
author: Charles Taragin and Romeo Ignacio
---

```{r setup, include=FALSE}
library(tidycensus)
library(tidyverse)
library(sf)
library(dplyr)
library(readxl)
library(knitr)
library(kableExtra)
library(vtable)
library(stringr)

knitr::opts_chunk$set(echo = F, message = F)
```


### Summary Statistics


```{r map_data, results = 'hide'}
### Step 1: Read in and graph data
csa_shp <- get_acs(
  geography = "combined statistical area",
  variables = "B19013_001",
  geometry = TRUE,
  survey = "acs1",
  year = 2019
) %>%
  select(GEOID,NAME,geometry) 

cbsa_shp <- get_acs(
  geography = "cbsa",
  variables = "B19013_001",
  geometry = TRUE,
  survey = "acs1",
  year = 2019
) %>%
  select(GEOID,NAME,geometry) 

# Deleted option: cbsa

county_shp <- get_acs(
  geography = "county",
  variables = "B19013_001",
  geometry = TRUE,
  survey = "acs1",
  year = 2019
) %>%
  select(GEOID,NAME,geometry)

raw <- read_xlsx("/fsr/project4/Charles/bargaining_convex/trash/Copy of WBJ_Disposal_Sites_2019.xlsx",skip=3)

## Clean up raw file names

raw_uniq_own_nms <- raw %>% 
  filter(Type=="LF"|Family=="LF"|Type=="TS"|Family=="TS") %>%
  select(`Owner Code`,`Owner Entity`,Type,Family) %>%
  unique() %>%
  mutate(`Owner Full Name`= ifelse(is.na(`Owner Code`),"",`Owner Entity`),
    `Owner Code`=ifelse(is.na(`Owner Code`),`Owner Entity`,`Owner Code`)) %>%
  group_by(`Owner Code`)  %>%
  select(`Owner Code`) %>%
  arrange(`Owner Code`) %>%
  unique()

write.csv(raw_uniq_own_nms,"/fsr/project4/Charles/bargaining_convex/trash/owner_nms_raw.csv")

raw_uniq_op_nms <- raw %>% 
  filter(Type=="LF"|Family=="LF"|Type=="TS"|Family=="TS") %>%
  select(`Operator Code`,`Operator Entity`,Type,Family) %>%
  unique() %>%
  mutate(
    `Operator Code`=ifelse(is.na(`Operator Code`),`Operator Entity`,`Operator Code`)) %>%
  group_by(`Operator Code`)  %>%
  select(`Operator Code`) %>%
  arrange(`Operator Code`) %>%
  unique()

write.csv(raw_uniq_op_nms,"/fsr/project4/Charles/bargaining_convex/trash/operator_nms_raw.csv")

# Clean for owner
raw_uniq_own_nms <- raw %>% 
  filter(Type=="LF"|Family=="LF"|Type=="TS"|Family=="TS") %>%
  select(`Owner Code`,`Owner Entity`,Type,Family) %>%
  unique() %>%
  mutate(`Owner Code`=ifelse(is.na(`Owner Code`),`Owner Entity`,`Owner Code`)) %>%
  group_by(`Owner Code`) %>%
  select(`Owner Code`) %>%
  mutate(`Owner Code`=str_replace_all(`Owner Code`,"Tidewater Fiber Corp","Tidewater Fibre Corp"),
         `Owner Code`=str_replace_all(`Owner Code`,"Town of Bethleham","Town of Bethlehem"),
         `Owner Code`=str_replace_all(`Owner Code`,regex("ABC Disposal Systems"),"ABC"),
         `Owner Code`=toupper(`Owner Code`),
         `Owner Code`=str_replace_all(`Owner Code`,"\\.",""),
         `Owner Code`=str_replace_all(`Owner Code`,"\\,",""),
         `Owner Code`=str_replace_all(`Owner Code`,regex(" inc\\b",ignore_case=T),""),
         `Owner Code`=str_replace_all(`Owner Code`,regex(" corp\\b",ignore_case=T),""),
         `Owner Code`=str_replace_all(`Owner Code`,regex(" co\\b",ignore_case=T),""),
         `Owner Code`=str_replace_all(`Owner Code`,regex(" company\\b",ignore_case=T),""),
         `Owner Code`=str_replace_all(`Owner Code`,regex(" corporation\\b",ignore_case=T),""),
         `Owner Code`=str_replace_all(`Owner Code`,regex(" LLC\\b",ignore_case=T),""),
         `Owner Code`=str_replace_all(`Owner Code`,regex(" & "),"&"),
         `Owner Code`=str_replace_all(`Owner Code`,regex("LP\\b"),""),
         `Owner Code`=str_squish(`Owner Code`)) %>%
  unique()

  #Clean up certain strings
 


raw <- raw %>%
  mutate(`Operator Code`=ifelse(is.na(`Operator Code`),`Operator Entity`,`Operator Code`)) %>%
  mutate(`Operator Code`=str_replace_all(`Operator Code`,"Tidewater Fiber Corp","Tidewater Fibre Corp"),
         `Operator Code`=str_replace_all(`Operator Code`,"Angelo's Recycled Materials - Tampa Recycling Facility","Angelo's Recycled Materials"),
         `Operator Code`=str_replace_all(`Operator Code`,regex("ABC Disposal Systems"),"ABC"),
         `Operator Code`=str_replace_all(`Operator Code`,regex("Athens Services"),"ATHEN"),
         `Operator Code`=str_replace(`Operator Code`,"Monadnock Disposal Service Inc.",	
"Monadnock Disposal Services"),
         `Operator Code`=str_replace(`Operator Code`,"Southern Disposal Services","Southern Disposal Service"),
         `Operator Code`=str_replace(`Operator Code`,"Vogel Disposal Service","Vogel Disposal"),
         `Operator Code`=str_replace(`Operator Code`,"Strategic Materials","Strategic Material"),
         `Operator Code`=toupper(`Operator Code`),
         `Operator Code`=str_replace_all(`Operator Code`,"\\.",""),
         `Operator Code`=str_replace_all(`Operator Code`,"\\,",""),
         `Operator Code`=str_replace_all(`Operator Code`,"-"," "),
         `Operator Code`=str_replace_all(`Operator Code`,regex(" inc\\b",ignore_case=T),""),
         `Operator Code`=str_replace_all(`Operator Code`,regex(" corp\\b",ignore_case=T),""),
         `Operator Code`=str_replace_all(`Operator Code`,regex(" co\\b",ignore_case=T),""),
         `Operator Code`=str_replace_all(`Operator Code`,regex(" company\\b",ignore_case=T),""),
         `Operator Code`=str_replace_all(`Operator Code`,regex(" corporation\\b",ignore_case=T),""),
         `Operator Code`=str_replace_all(`Operator Code`,regex(" LLC\\b",ignore_case=T),""),
         `Operator Code`=str_replace_all(`Operator Code`,regex(" & "),"&"),
         `Operator Code`=str_replace_all(`Operator Code`,regex("LP\\b"),""),
         `Operator Code`=str_squish(`Operator Code`)) 
  
raw <- raw %>%
  mutate(`Owner Code`=ifelse(is.na(`Owner Code`),`Owner Entity`,`Owner Code`)) %>%
  mutate(`Owner Code`=str_replace_all(`Owner Code`,"Tidewater Fiber Corp","Tidewater Fibre Corp"),
         `Owner Code`=str_replace_all(`Owner Code`,"Town of Bethleham","Town of Bethlehem"),
         `Owner Code`=str_replace_all(`Owner Code`,regex("ABC Disposal Systems"),"ABC"),
         `Owner Code`=toupper(`Owner Code`),
         `Owner Code`=str_replace_all(`Owner Code`,"\\.",""),
         `Owner Code`=str_replace_all(`Owner Code`,"\\,",""),
         `Owner Code`=str_replace_all(`Owner Code`,regex(" inc\\b",ignore_case=T),""),
         `Owner Code`=str_replace_all(`Owner Code`,regex(" corp\\b",ignore_case=T),""),
         `Owner Code`=str_replace_all(`Owner Code`,regex(" co\\b",ignore_case=T),""),
         `Owner Code`=str_replace_all(`Owner Code`,regex(" company\\b",ignore_case=T),""),
         `Owner Code`=str_replace_all(`Owner Code`,regex(" corporation\\b",ignore_case=T),""),
         `Owner Code`=str_replace_all(`Owner Code`,regex(" LLC\\b",ignore_case=T),""),
         `Owner Code`=str_replace_all(`Owner Code`,regex(" & "),"&"),
         `Owner Code`=str_replace_all(`Owner Code`,regex("LP\\b"),""),
         `Owner Code`=str_squish(`Owner Code`)) 

#Bestway Disposal (Different owner???)
#Monadnock Disposal Services (Diferent owner???)
#Texas Disposal Systems vs Texas Disposal Systems Inc.
operator_names <- raw %>%
  filter(Type=="LF"|Family=="LF"|Type=="TS"|Family=="TS") %>%
  select(`Operator Entity`) %>%
  unique()
#Willimantic Waste Paper Co For operator (Different operator???)
#Bestway Disposal (Different operator???)

disposal_df <- raw %>%
  select(Code,Location,City,County,State,Zip,Longitude,Latitude,Code,Type,Family,`Waste Shed`,`Owner Code`,`Owner Entity`,`Operator Code`,`Operator Entity`,`Total of All Wastes (tons/day)`) %>%
  rename(Waste_Shed = `Waste Shed`,
         Owner_Code = `Owner Code`,
         Owner_Entity = `Owner Entity`,
         Operator_Code = `Operator Code`,
         Operator_Entity=`Operator Entity`) #%>%
  # mutate(Owner_Code=Owner_Entity,
  #        Operator_Code=Operator_Entity)

## Determine level of aggregation


```




```{r}
### Step 2: Merge in shape files
## Merge all disposal data
disposal_df_shp <- st_as_sf(disposal_df,coords=c("Longitude","Latitude"), crs=4326) %>% #crs=4269)
  st_transform(crs=4269)
############### CSA ###############
intersect_df <- st_join(disposal_df_shp,csa_shp,left=T,join=st_intersects) %>%
    rename(cbsa=NAME) %>%
    mutate(st_cnty=paste(County,State,sep = ":"),
    market=ifelse(is.na(cbsa),st_cnty,cbsa),
    iscsa=!is.na(cbsa)) %>%
    st_drop_geometry()
############### CBSA ###############
cbsa_intersect_df <- st_join(disposal_df_shp,cbsa_shp,left=T,join=st_intersects) %>%
    rename(cbsa=NAME) %>%
    mutate(st_cnty=paste(County,State,sep = ":"),
    market=ifelse(is.na(cbsa),st_cnty,cbsa),
    iscbsa=!is.na(cbsa)) %>%
    st_drop_geometry()

############### County ###############
county_intersect_df <- st_join(disposal_df_shp,county_shp) %>%
  st_drop_geometry() %>%
  rename(county_shp=NAME) %>%
  mutate(county_same = str_detect(county_shp,County)) %>%
  relocate(county_shp,County,county_same) 

# prop.table(table(county_intersect_df$county_same==1))

## Create crosswalk
crosswalk_disposal_df <- intersect_df %>%
  select(Code,market)

write.csv(crosswalk_disposal_df,"/fsr/project4/Charles/bargaining_convex/trash/cbsa_disposal_cross.csv",row.names = F)
```

```{r, results ="hide"}
## Clean up data

intersect_df %>% filter(Type == "LF" & market == "Chattanooga, TN-GA Metro Area")

# Inquire about wasteshed and what to do if NA???
landfill_csa_df <- intersect_df %>%
  st_drop_geometry() %>%
  filter(Type=="LF"|Family=="LF"|Type=="TS"|Family=="TS") %>% # Step 1: Keep only LF basde on either Type or Family
  filter(Waste_Shed!="Exclusive or Captive"|is.na(Waste_Shed)) %>% # Step 2: Drop all observations labelled "Exclusive or Captive" (1619 Observations)
  mutate(firm_name="") %>%
  select(Owner_Code,Owner_Entity,Operator_Code,Operator_Entity,market,st_cnty,County,State,`Total of All Wastes (tons/day)`,iscsa) 

landfill_cbsa_df <- cbsa_intersect_df %>%
  st_drop_geometry() %>%
  filter(Type=="LF"|Family=="LF") %>% # Step 1: Keep only LF basde on either Type or Family
  filter(Waste_Shed!="Exclusive or Captive"|is.na(Waste_Shed)) %>% # Step 2: Drop all observations labelled "Exclusive or Captive" (1619 Observations)
  select(Owner_Code,Owner_Entity,Operator_Code,Operator_Entity,market,st_cnty,County,State,`Total of All Wastes (tons/day)`,iscbsa) 

```

This is on the Owner Code-Operator Code level or Owner Entity-Operator Entity level if code does not exist.  Let's first look at number of markets that are in a CSA and number of markets that are county based as they do not fall in a CSA.  We see that only 11% of markets are CSA market based. 
```{r}
### Get number of landsfill sights that don't match
sum_landfill_all <- landfill_csa_df %>%
  mutate(coor_exis=ifelse(market!=st_cnty,"CSA","County")) %>%
  st_drop_geometry() #%>%
  # select(market,coor_exis) %>% # New line, can delete to get old calculation
  # unique()  # New line, can delete to get old calculation
  
sum_landfill <- sum_landfill_all  %>%
  select(coor_exis) %>%
  group_by(coor_exis) %>%
  summarise(count=n()) %>%
  ungroup() %>%
  mutate(per_count=100*prop.table(count))

#market!=st_cnty
sum_landfill %>%
  kbl(col.names=c("Type","Count","Percent"),
      digits=0,
      caption = "# Landfills Market Types") %>%
  kable_classic_2(full_width = F)

```
Now Let's decompose markets that have 1 landfill and > 1 landfill.  We see about 59% of markets have only one landfill.  

```{r}
## Create summary statistics (On MSA-Owner-Operator Lvl)
landfill_sum_csa <- landfill_csa_df %>%
  ungroup() %>%
  group_by(market,Owner_Code,Operator_Code) %>%
  summarise(count=n(),
            total_waste=sum(`Total of All Wastes (tons/day)`), .groups="keep")

landfill_sum_cbsa <- landfill_cbsa_df %>%
  ungroup() %>%
  group_by(market,Owner_Code,Operator_Code) %>%
  summarise(count=n(),
            total_waste=sum(`Total of All Wastes (tons/day)`), .groups="keep")

write.csv(landfill_sum_csa,"/fsr/project4/Charles/bargaining_convex/trash/landfill_final.csv",row.names = F)

# On CSA Level
landfill_mkt_cnt_csa <- landfill_sum_csa %>%
  ungroup() %>%
  group_by(market) %>%
  summarise(count=n())
# On CBSA Level
landfill_mkt_cnt_cbsa <- landfill_sum_cbsa %>%
  ungroup() %>%
  group_by(market) %>%
  summarise(count=n())

landfill_prop_csa <- landfill_mkt_cnt_csa %>%
  ungroup %>%
  mutate(several_markets=ifelse(count>1,"Several Landfills","One Landfill"))

landfill_prop_cbsa <- landfill_mkt_cnt_cbsa %>%
  ungroup %>%
  mutate(several_markets=ifelse(count>1,"Several Landfills","One Landfill"))

# Get summary statistics of landfills
sum_landfill <- landfill_csa_df %>%
  mutate(coor_exis=ifelse(market!=st_cnty,"CSA","County")) %>%
  st_drop_geometry() %>%
  select(coor_exis) %>%
  group_by(coor_exis) %>%
  summarise(count=n()) %>%
  ungroup() %>%
  mutate(per_count=100*prop.table(count))

landfill_prop_csa %>%
  group_by(several_markets) %>%
  summarise(count=n()) %>%
  mutate(per_count=100*prop.table(count)) %>% 
  kbl(col.names=c("Type","Count","Percent"),
      digits=0,
      format.args = list(big.mark = ","),
      caption="Markets with as least one Landfill") %>%
  kable_classic_2(full_width = F)
# summary(landfill_sum$count)
# quantile(landfill_sum$count,seq(0,1,0.05))

 
```

```{r}
## Create HHI Level data
### On CSA Level ###
landfill_shrs_csa <- landfill_csa_df %>%
  ungroup() %>%
  group_by(Owner_Code,Operator_Code,market,iscsa) %>% # Aggregate on Market level, Owner Entity, Operator level
  summarise(waste_own = sum(`Total of All Wastes (tons/day)`), .groups="keep") %>%
  ungroup() %>%
  group_by(market) %>% # Aggregate on Market
  mutate(total_waste = sum(waste_own),
         waste_shr = 100*(waste_own/total_waste),
         waste_hhi = sum(waste_shr^2))
### On CBSA Level ###
landfill_shrs_cbsa <- landfill_cbsa_df %>%
  ungroup() %>%
  group_by(Owner_Code,Operator_Code,market,iscbsa) %>% # Aggregate on Market level, Owner Entity, Operator level
  summarise(waste_own = sum(`Total of All Wastes (tons/day)`), .groups="keep") %>%
  ungroup() %>%
  group_by(market) %>% # Aggregate on Market
  mutate(total_waste = sum(waste_own),
         waste_shr = 100*(waste_own/total_waste),
         waste_hhi = sum(waste_shr^2)) ## Have NA remove option

chat <- filter(intersect_df,grepl("Chattanooga",market))

write.csv(chat,"/fsr/project4/Charles/bargaining_convex/trash/chat.csv",row.names = F)

### CSA ### (921 markets)
landfill_hhi_csa_df  <- landfill_shrs_csa %>% 
  select(market,waste_hhi,iscsa) %>% # Keep market level information and filter out duplicates
  unique() 

write.csv(landfill_hhi_csa_df,"/fsr/project4/Charles/bargaining_convex/trash/landfill_hhi_final.csv",row.names = F)

### Export Chatanooga CSA ###
chat_shrs <- landfill_shrs_csa %>%
  filter(market=="Chattanooga-Cleveland-Dalton, TN-GA CSA")

write.csv(chat_shrs,"/fsr/project4/Charles/bargaining_convex/trash/chat_share.csv",row.names=F)

### CBSA ### (1088 markets)
landfill_hhi_cbsa_df <- landfill_shrs_cbsa %>% 
  select(market,waste_hhi,iscbsa) %>% # Keep market level information and filter out duplicates
  unique()

```

Now we will look at summary stats of HHI landfill data on the CSA level.  We have `r nrow(landfill_hhi_csa_df)` total markets on the CSA level in the dataset but only `r sum(!is.na(landfill_hhi_csa_df$waste_hhi))` analyzed.  This can be explained as `r sum(is.na(landfill_hhi_csa_df$waste_hhi))` markets have no waste produced, which produces NAs when calculating for HHI. 

```{r message=FALSE, warning=F}
graph_data <- landfill_hhi_csa_df %>% select(market,waste_hhi)
st(graph_data,out="kable",labels=c("Waste HHI"),
   summ=c('notNA(x)','min(x)','pctile(x)[25]' ,'median(x)','pctile(x)[75]', 'max(x)','mean(x)', 'sd(x)'),
   summ.names=c('N','Min','Pctile[25]' ,'Median','Pctile[75]', 'Max','Mean', 'Sd'),
   title = "CSA HHI Summary Statistics") %>%
  kable_classic_2(full_width = F)
  


```
Now we will look at summary stats of HHI conditional on if the market is in a CSA or if it's not.

```{r}
### Custom summarise function command


csa_grp_landfill <- landfill_hhi_csa_df %>% 
  mutate(`Type`=ifelse(iscsa==1,"CSA","County")) %>%
  group_by(Type) %>%
  drop_na %>%
  summarise(`N`=n(),
  `Min`=min(waste_hhi),
  `Pctile[25]`=pctile(waste_hhi)[25],
  `Median`=median(waste_hhi),
  `Pctile[75]`=pctile(waste_hhi)[75],
  `Max`=max(waste_hhi),
  `Mean`=mean(waste_hhi),
  `Sd`=sd(waste_hhi)) %>%
  kbl(digits=2,
      caption = "Market Types") %>%
  kable_classic_2(full_width = F)

csa_grp_landfill

# csa_grp_landfill <- landfill_hhi_csa_df
# st(csa_grp_landfill,group = "In CSA",group.long=T,out="kable",labels=c("Waste HHI"),title="CSA vs County HHIs Summary Statistics",summ=c('min(x)','pctile(x)[25]' ,'median(x)','pctile(x)[75]', 'max(x)','mean(x)', 'sd(x)'),factor.numeric=T) %>%
#   kable_classic_2(full_width = F)
```



```{r}

csa_grp_landfill <- landfill_hhi_csa_df %>% rename(`In CSA`=iscsa)

# tapply(landfill_hhi_csa_df$waste_hhi,landfill_hhi_csa_df$iscsa,summary)
```
Now let's look at the deciles of HHIs on the CSA level below:
```{r}

# quantile(landfill_hhi_csa_df$waste_hhi,seq(0,1,0.1),na.rm=T)

# quantile(landfill_hhi_cbsa_df$waste_hhi,seq(0,1,0.1),na.rm=T)
df_1 <- landfill_hhi_csa_df %>%
  mutate(`Type`="CSA") %>%
  select(-iscsa) %>%
  left_join(landfill_prop_csa) 

df_2 <- landfill_hhi_cbsa_df %>%
  mutate(`Type`="CBSA") %>%
  select(-iscbsa) %>%
  left_join(landfill_prop_cbsa) 

landfill_csa_cbsa_df <- bind_rows(df_1,df_2)

landfill_csa <- df_1

landfill_csa %>%
  group_by(`Type`) %>%
  summarise(q=list(quantile(waste_hhi,seq(0,1,0.1),na.rm=T))) %>%
  unnest_wider(q) %>% 
  arrange(desc(`Type`)) %>%
  kbl(full_wdith=F,
      digits=0,
      caption = "CSA HHIs") %>%
  kable_classic_2(full_width = F)





```

The count of markets on the CSA level is `r nrow(landfill_hhi_csa_df)`  (including county level markets if no CSA exists).

Now let's look at the HHIs of only markets with several landfills.  
```{r}
non_mono_landfill_csa_cbsa_df <- landfill_csa_cbsa_df %>%
  filter(several_markets=="Several Landfills")

non_mono_landfill_csa_df <- non_mono_landfill_csa_cbsa_df %>%
  filter(waste_hhi<10000 & Type == "CSA")

non_mono_landfill_cbsa_df <- non_mono_landfill_csa_cbsa_df %>%
  filter(several_markets=="Several Landfills" & Type == "CBSA")

non_mono_landfill_csa_df %>%
  group_by(`Type`) %>%
  summarise(q=list(quantile(waste_hhi,seq(0,1,0.1),na.rm=T))) %>%
  unnest_wider(q) %>% 
  arrange(desc(`Type`)) %>%
  kbl(full_wdith=F,
      digits=0,
      caption = "CSA HHIs") %>%
  kable_classic_2(full_width = F)
```

The count of markets with more than one landfill on the CSA level is `r nrow(non_mono_landfill_csa_df)`  (including county level markets if no CSA exists).

```{r}

## Data check if all percentages in a market equal 1
chk_lf_df <- landfill_shrs_csa %>% 
  group_by(market) %>%
  mutate(chk_per=sum(waste_shr)) %>%
  ungroup() %>%
  select(chk_per) %>%
  unique()
```

### Graphs
```{r}
## Count of firms
cnt_landfill_csa <- landfill_shrs_csa %>% 
  ungroup() %>%
  group_by(market) %>%
  summarise(landfills_cnt = n())

## CSA level bar chart data
bar_csa <- landfill_shrs_csa %>% 
  ungroup() %>%
  group_by(market) %>%
  summarise(landfills_cnt = n()) %>%
  ungroup() %>%
  group_by(landfills_cnt) %>%
  summarise(freq=n()) %>%
  mutate(grp_lbls = ifelse(landfills_cnt>=10,"10+",landfills_cnt)) %>%
  ungroup() %>%
  group_by(grp_lbls) %>%
  summarise(freq=sum(freq)) %>%
  mutate(lvl="CSA")

## CBSA level bar chart data
bar_cbsa <- landfill_shrs_cbsa %>% 
  ungroup() %>%
  group_by(market) %>%
  summarise(landfills_cnt = n()) %>%
  ungroup() %>%
  group_by(landfills_cnt) %>%
  summarise(freq=n()) %>%
  mutate(grp_lbls = ifelse(landfills_cnt>=10,"10+",landfills_cnt)) %>%
  ungroup() %>%
  group_by(grp_lbls) %>%
  summarise(freq=sum(freq)) %>%
  mutate(lvl="CBSA")

combine_csa_cbsa <- bind_rows(bar_csa,bar_cbsa)

csa_chart <- bar_csa
```

Below is a bar-chart of frequency of landfills across markets.  About `r max(bar_csa$freq)` markets across a CSA only have 1 landfill that serves the market.  The highest number of firms in a market is `r max(cnt_landfill_csa$landfills_cnt)` in the New York-Newark CSA.  `r  sum(cnt_landfill_csa$landfills_cnt>=20)` of these markets have a firm count greater than 20.
```{r}
positions = c(seq(1,9,1),"10+")
ggplot(csa_chart,aes(x=grp_lbls,y=freq)) +
  geom_bar(stat="identity") +
  theme_bw() + 
  geom_text(aes(label = freq), hjust = -0.05, colour = "black") +
  geom_hline(yintercept=0,color="gold",linetype='dashed') +
  coord_flip() +  
  scale_x_discrete(limits = positions) +
  xlab("Landfill Counts") +
  ylab("Frequency") + 
  ggtitle("Freq. of Landfills by CSA Based Market") +
  labs(caption = "Source: Waste Business Journal's: Directory of Waste Processing & Disposal Sites 2019")
## Bar chart CSA

# ggplot(data=bar_csa, aes(x=grp_lbls,y=freq)) +
#   geom_bar(stat="identity") + 
#   ggtitle("CSA Freq. of Landfills by Market") +
#   xlab("Landfill Counts") +
#   ylab("Frequency") + 
#   scale_x_discrete(limits = positions) + 
#   theme_bw()
```



